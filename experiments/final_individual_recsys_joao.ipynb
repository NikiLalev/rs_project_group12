{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Individual Recommender System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Pandas Display all columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/hfw66rw97sl45x98mmd_vs4r0000gn/T/ipykernel_56438/1459283311.py:2: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ratings_df_slim = pd.read_csv('../dataset/XWines_Slim_150K_ratings.csv')\n",
      "/var/folders/9n/hfw66rw97sl45x98mmd_vs4r0000gn/T/ipykernel_56438/1459283311.py:3: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ratings_df_full = pd.read_csv('../dataset/XWines_Full_21M_ratings.csv')\n"
     ]
    }
   ],
   "source": [
    "# Load the ratings data\n",
    "ratings_df_slim = pd.read_csv('../dataset/XWines_Slim_150K_ratings.csv')\n",
    "ratings_df_full = pd.read_csv('../dataset/XWines_Full_21M_ratings.csv')\n",
    "\n",
    "# Load the wines data\n",
    "wines_df_slim = pd.read_csv('../dataset/XWines_Slim_1K_wines.csv')\n",
    "wines_df_full = pd.read_csv('../dataset/XWines_Full_100K_wines.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping some of the Columns in the wines_df\n",
    "# Some are irrelevant for analysis (like the website) and some will just be repeated info (like the Code and Country)\n",
    "wine_columns_to_drop_repeated = ['Website', 'Code', 'RegionID', 'WineryID', 'WineName', 'RegionName', 'WineryName']\n",
    "wines_df_slim.drop(columns=wine_columns_to_drop_repeated, inplace=True)\n",
    "wines_df_full.drop(columns=wine_columns_to_drop_repeated, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the Features we will not use for ML due to the extremely high dimensionality\n",
    "wine_columns_to_drop_high_dimensionality = ['Grapes'] # Too many unique values\n",
    "wines_df_slim.drop(columns=wine_columns_to_drop_high_dimensionality, inplace=True)\n",
    "wines_df_full.drop(columns=wine_columns_to_drop_high_dimensionality, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string to list\n",
    "import ast\n",
    "\n",
    "wines_df_slim['Harmonize'] = wines_df_slim['Harmonize'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "wines_df_slim['Vintages'] = wines_df_slim['Vintages'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "wines_df_slim['Vintages'] = wines_df_slim['Vintages'].apply(lambda x: [int(v) for v in ast.literal_eval(x)] if isinstance(x, str) else x)\n",
    "\n",
    "wines_df_full['Harmonize'] = wines_df_full['Harmonize'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "wines_df_full['Vintages'] = wines_df_full['Vintages'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "wines_df_full['Vintages'] = wines_df_full['Vintages'].apply(lambda x: [int(v) for v in ast.literal_eval(x)] if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing Vintages\n",
    "def process_vintages(vintages):\n",
    "    # Remove \"N.V.\" from the list\n",
    "    filtered_vintages = [vintage for vintage in vintages if vintage != \"N.V.\"]\n",
    "\n",
    "    # Calculate the number of vintages\n",
    "    num_vintages = len(filtered_vintages)\n",
    "\n",
    "    # Find the oldest and most recent vintages\n",
    "    oldest_vintage = min(filtered_vintages) if filtered_vintages else 0\n",
    "    most_recent_vintage = max(filtered_vintages) if filtered_vintages else 0\n",
    "    vintage_range = most_recent_vintage - oldest_vintage\n",
    "\n",
    "    return num_vintages, oldest_vintage, most_recent_vintage, vintage_range\n",
    "\n",
    "# Apply the function to each row for both dataset versions\n",
    "wines_df_slim[['num_vintages', 'oldest_vintage', 'most_recent_vintage', 'vintage_range']] = wines_df_slim['Vintages'].apply(process_vintages).tolist()\n",
    "wines_df_full[['num_vintages', 'oldest_vintage', 'most_recent_vintage', 'vintage_range']] = wines_df_full['Vintages'].apply(process_vintages).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original Vintages column for both datasets, since we susbtituted with the new columns \n",
    "wines_df_slim.drop(columns=['Vintages'], inplace=True)\n",
    "wines_df_full.drop(columns=['Vintages'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some renaming if we want to use the lenskit later:\n",
    "ratings_df_slim = ratings_df_slim.rename(columns={'UserID': 'user', 'WineID': 'item', 'Rating': 'rating', 'Date': 'timestamp'})\n",
    "ratings_df_full = ratings_df_full.rename(columns={'UserID': 'user', 'WineID': 'item', 'Rating': 'rating', 'Date': 'timestamp'})\n",
    "\n",
    "\n",
    "wines_df_slim = wines_df_slim.rename(columns={'WineID': 'item'})\n",
    "wines_df_full = wines_df_full.rename(columns={'WineID': 'item'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode 'Harmonize' column into individual rows\n",
    "wines_exploded_slim = wines_df_slim.explode('Harmonize')\n",
    "wines_exploded_full = wines_df_full.explode('Harmonize')\n",
    "\n",
    "# One-hot encode the 'Harmonize' column with the desired prefix\n",
    "harmonize_one_hot_slim = pd.get_dummies(wines_exploded_slim['Harmonize'], prefix='harmonize_with')\n",
    "harmonize_one_hot_full = pd.get_dummies(wines_exploded_full['Harmonize'], prefix='harmonize_with')\n",
    "\n",
    "# Group by 'item' and sum to combine back into single rows per item\n",
    "harmonize_one_hot_grouped_slim = harmonize_one_hot_slim.groupby(wines_exploded_slim['item']).sum()\n",
    "harmonize_one_hot_grouped_full = harmonize_one_hot_full.groupby(wines_exploded_full['item']).sum()\n",
    "\n",
    "# Merge the one-hot encodings with the original DataFrame\n",
    "wines_df_slim = wines_df_slim.merge(harmonize_one_hot_grouped_slim, left_on='item', right_index=True, how='left')\n",
    "wines_df_full = wines_df_full.merge(harmonize_one_hot_grouped_full, left_on='item', right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the Harmonize Column on both versions for the wines\n",
    "wines_df_slim.drop(columns=['Harmonize'], inplace=True)\n",
    "wines_df_full.drop(columns=['Harmonize'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-apply One-Hot Encoding with dtype=int for wines_df_slim\n",
    "wines_df_slim = pd.get_dummies(\n",
    "    wines_df_slim,\n",
    "    columns=['Type', 'Elaborate', 'Body', 'Acidity', 'Country'],\n",
    "    dtype=int\n",
    ")\n",
    "\n",
    "# Re-apply One-Hot Encoding with dtype=int for wines_df_full\n",
    "wines_df_full = pd.get_dummies(\n",
    "    wines_df_full,\n",
    "    columns=['Type', 'Elaborate', 'Body', 'Acidity', 'Country'],\n",
    "    dtype=int\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing One Hot Encodding for the Categorical Features\n",
    "wines_df_slim = pd.get_dummies(wines_df_slim, columns=['Type', 'Elaborate', 'Body', 'Acidity', 'Country'])\n",
    "wines_df_full = pd.get_dummies(wines_df_full, columns=['Type', 'Elaborate', 'Body', 'Acidity', 'Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wines_df_slim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the Numerical Features\n",
    "numerical_features_to_scale = ['ABV', 'num_vintages', 'oldest_vintage', 'most_recent_vintage', 'vintage_range']\n",
    "\n",
    "# Scale the numerical features for both datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_for_slim = StandardScaler()\n",
    "wines_df_slim[numerical_features_to_scale] = scaler_for_slim.fit_transform(wines_df_slim[numerical_features_to_scale])\n",
    "\n",
    "scaler_for_full = StandardScaler()\n",
    "wines_df_full[numerical_features_to_scale] = scaler_for_full.fit_transform(wines_df_full[numerical_features_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How the Wines Dataset looks for ML\n",
    "wines_df_slim.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Mask for the Ratings\n",
    "* 1 - 3.5 - 0\n",
    "* 4 - 4.5 - 1\n",
    "* 4.5 - 5 - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go through the Ratings on both datasets and subsitute the values based on conditions. \n",
    "# <=3.5 becomes 0\n",
    "# 4 becomes 1\n",
    "# >= 4.5 becomes 2\n",
    "def label_rating(rating):\n",
    "    if rating <= 3.5: #~41%\n",
    "        return 0\n",
    "    elif rating == 4.0: #~36%\n",
    "        return 1\n",
    "    elif 4.5 <= rating <= 5.0: #~22%\n",
    "        return 2\n",
    "\n",
    "# Apply the function to create the new column 'rating_label'\n",
    "ratings_df_slim['rating_label'] = ratings_df_slim['rating'].apply(label_rating)\n",
    "ratings_df_full['rating_label'] = ratings_df_full['rating'].apply(label_rating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df_slim.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wines_df_slim.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content Based Classifier - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue from where you left off\n",
    "\n",
    "# Merge the ratings with the wine features\n",
    "data = ratings_df_slim.merge(wines_df_slim, on='item')\n",
    "\n",
    "# List of wine feature columns (exclude 'item' and any other non-feature columns if necessary)\n",
    "wine_feature_columns = wines_df_slim.columns.tolist()\n",
    "wine_feature_columns.remove('item')\n",
    "\n",
    "# Initialize a list to store evaluation metrics\n",
    "metrics_list = []\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ndcg_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Get the list of unique users\n",
    "users = data['user'].unique()\n",
    "\n",
    "# Iterate over each user\n",
    "for user_id in tqdm(users, desc='Processing Users'):\n",
    "    # Get the data for the current user\n",
    "    user_data = data[data['user'] == user_id]\n",
    "    \n",
    "    # Skip users with insufficient data\n",
    "    if len(user_data) < 5:\n",
    "        continue  # Skip users with less than 5 ratings\n",
    "    \n",
    "    # Prepare features (X) and target variable (y)\n",
    "    # X should contain only the wine features\n",
    "    X = user_data[wine_feature_columns]\n",
    "    y = user_data['rating_label']\n",
    "    \n",
    "    # Ensure that X contains only wine features\n",
    "    # Optionally, print X.columns to verify\n",
    "    # print(\"Features used for training:\", X.columns.tolist())\n",
    "    \n",
    "    # Split into training and testing sets, stratified on 'rating_label'\n",
    "    try:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "    except ValueError:\n",
    "        # If stratification is not possible due to class imbalance, skip this user\n",
    "        continue\n",
    "    \n",
    "    # Ensure all features are numerical\n",
    "    X_train = X_train.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "    X_test = X_test.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "    \n",
    "    # Train the Decision Tree Classifier with max_depth=3\n",
    "    clf = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the items not rated by the user\n",
    "    user_rated_items = user_data['item'].unique()\n",
    "    all_items = wines_df_slim['item'].unique()\n",
    "    items_to_predict = np.setdiff1d(all_items, user_rated_items)\n",
    "    \n",
    "    # Get features for the items to predict\n",
    "    items_to_predict_df = wines_df_slim[wines_df_slim['item'].isin(items_to_predict)]\n",
    "    \n",
    "    # Prepare features for prediction\n",
    "    X_predict = items_to_predict_df[wine_feature_columns]\n",
    "    \n",
    "    # Ensure that the feature columns match those used in training\n",
    "    missing_cols = set(X_train.columns) - set(X_predict.columns)\n",
    "    for col in missing_cols:\n",
    "        X_predict[col] = 0  # Add missing columns with default value 0\n",
    "    X_predict = X_predict[X_train.columns]  # Reorder columns\n",
    "    \n",
    "    # Ensure all features are numerical\n",
    "    X_predict = X_predict.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "    \n",
    "    # Predict the 'rating_label' for these items\n",
    "    y_pred = clf.predict(X_predict)\n",
    "    \n",
    "    # Create a DataFrame with the predictions\n",
    "    predictions_df = pd.DataFrame({\n",
    "        'item': items_to_predict_df['item'],\n",
    "        'predicted_rating_label': y_pred\n",
    "    })\n",
    "    \n",
    "    # Map the predicted labels to scores for ranking (higher labels indicate higher preference)\n",
    "    predictions_df['predicted_score'] = predictions_df['predicted_rating_label']\n",
    "    \n",
    "    # Get the top N recommendations\n",
    "    top_n = 10\n",
    "    recommendations = predictions_df.sort_values(by='predicted_score', ascending=False).head(top_n)\n",
    "    \n",
    "    # Prepare ground truth for evaluation\n",
    "    # Get the items in the test set with 'rating_label' >= 1 (considered relevant)\n",
    "    test_items = user_data.loc[y_test.index, 'item'].values\n",
    "    relevant_items = user_data.loc[y_test.index][user_data['rating_label'] >= 1]['item'].values\n",
    "    \n",
    "    # Recommended items\n",
    "    recommended_items = recommendations['item'].values\n",
    "    \n",
    "    # Compute evaluation metrics\n",
    "    # Precision@N\n",
    "    hits = [1 if item in relevant_items else 0 for item in recommended_items]\n",
    "    num_hits = sum(hits)\n",
    "    precision = num_hits / top_n if top_n > 0 else 0\n",
    "    \n",
    "    # Recall@N\n",
    "    num_relevant_items = len(relevant_items)\n",
    "    recall = num_hits / num_relevant_items if num_relevant_items > 0 else 0\n",
    "    \n",
    "    # NDCG@N\n",
    "    relevance_scores = [1 if item in relevant_items else 0 for item in recommended_items]\n",
    "    if sum(relevance_scores) > 0:\n",
    "        ndcg = ndcg_score([relevance_scores], [relevance_scores], k=top_n)\n",
    "    else:\n",
    "        ndcg = 0.0\n",
    "    \n",
    "    # Store the metrics\n",
    "    metrics_list.append({\n",
    "        'user': user_id,\n",
    "        'Precision@{}'.format(top_n): precision,\n",
    "        'Recall@{}'.format(top_n): recall,\n",
    "        'NDCG@{}'.format(top_n): ndcg\n",
    "    })\n",
    "\n",
    "# Create a DataFrame with the evaluation metrics\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "\n",
    "# Compute the average metrics\n",
    "average_metrics = metrics_df.mean(numeric_only=True)\n",
    "\n",
    "# Display the average metrics\n",
    "print(\"\\nAverage Metrics Across All Users:\")\n",
    "for metric_name, value in average_metrics.items():\n",
    "    print(f\"{metric_name}: {value:.4f}\")\n",
    "\n",
    "# Optionally, visualize the distribution of metrics\n",
    "metrics_melted = metrics_df.melt(\n",
    "    id_vars='user',\n",
    "    value_vars=['Precision@{}'.format(top_n), 'Recall@{}'.format(top_n), 'NDCG@{}'.format(top_n)],\n",
    "    var_name='Metric',\n",
    "    value_name='Score'\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='Metric', y='Score', data=metrics_melted)\n",
    "plt.title('Distribution of Evaluation Metrics Across Users')\n",
    "plt.xlabel('Metric')\n",
    "plt.ylabel('Score')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
